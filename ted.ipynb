{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Editor:**\n",
    "\n",
    "Anastasios Bazinis - 1115201500099"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepreparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize,WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,  TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('universal_tagset')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Create train an test Dataframes <br><br>\n",
    "**In column Comments**\n",
    "    - Remove links\n",
    "    - Replace unnecessary ascii characters with space\n",
    "    - Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv(\"data/train.csv\")\n",
    "te = pd.read_csv(\"data/impermium_verification_set.csv\")\n",
    "\n",
    "tr['Comment'] = tr['Comment'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "tr['Comment'] = tr['Comment'].str.lower()\n",
    "\n",
    "tr['Comment'] = tr['Comment'].str.replace(r'\\\\x..',\" \",regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r'\\\\u....',\" \",regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r'\\\\n',\" \",regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r'\\\\.',\" \",regex = True)\n",
    "\n",
    "\n",
    "te['Comment'] = te['Comment'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "te['Comment'] = te['Comment'].str.lower()\n",
    "\n",
    "te['Comment'] = te['Comment'].str.replace(r'\\\\x..',\" \",regex = True)\n",
    "te['Comment'] = te['Comment'].str.replace(r'\\\\u....',\" \",regex = True)\n",
    "te['Comment'] = te['Comment'].str.replace(r'\\\\n',\" \",regex = True)\n",
    "te['Comment'] = te['Comment'].str.replace(r'\\\\.',\" \",regex = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a list of every comment in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lowercase = []\n",
    "clean_test_words = []\n",
    "clean_test_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in te['Comment']:\n",
    "    test_lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(test_lowercase)):\n",
    "    \n",
    "    clean_test_words.append([token for token in test_lowercase[x] if token.isalpha()])\n",
    "    clean_test_words_str.append(\" \".join(clean_test_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a list of every comment in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase = []\n",
    "clean_words = []\n",
    "clean_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in tr['Comment']:\n",
    "    lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(lowercase)):\n",
    "    \n",
    "    clean_words.append([token for token in lowercase[x] if token.isalpha()])\n",
    "    clean_words_str.append(\" \".join(clean_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Naive Bayes classification for word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.52      1158\n",
      "           1       0.50      0.53      0.51      1077\n",
      "\n",
      "    accuracy                           0.52      2235\n",
      "   macro avg       0.52      0.52      0.52      2235\n",
      "weighted avg       0.52      0.52      0.52      2235\n",
      "\n",
      "0.5181208053691275\n",
      "0.5182302071383941\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(clean_words_str)\n",
    "T = vectorizer.transform(clean_test_words_str)\n",
    "\n",
    "X_train, Y_train = X.toarray(), tr['Insult'] \n",
    "X_test = T.toarray()\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "test_lowercase = []\n",
    "clean_test_words1 = []\n",
    "clean_test_words_str1 = []\n",
    "lemmatized_output_test = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "for word in te['Comment']:\n",
    "    test_lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "    \n",
    "i=0\n",
    "for x in range(0,len(test_lowercase)):\n",
    "    \n",
    "    clean_test_words1.append([token for token in test_lowercase[x] if token.isalpha()])\n",
    "    lemmatized_output_test.append([lemmatizer.lemmatize(w,pos = \"v\") for w in clean_test_words1[i]])\n",
    "    clean_test_words_str1.append(\" \".join(lemmatized_output_test[i]))\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lowercase = []\n",
    "clean_words1 = []\n",
    "clean_words_str1 = []\n",
    "lemmatized_output = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "for word in tr['Comment']:\n",
    "    lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(lowercase)):\n",
    "    \n",
    "    clean_words1.append([token for token in lowercase[x] if token.isalpha()])\n",
    "    lemmatized_output.append([lemmatizer.lemmatize(w,pos = \"v\") for w in clean_words1[i]])\n",
    "    clean_words_str1.append(\" \".join(lemmatized_output[i]))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.46      0.49      1158\n",
      "           1       0.50      0.57      0.53      1077\n",
      "\n",
      "    accuracy                           0.51      2235\n",
      "   macro avg       0.52      0.51      0.51      2235\n",
      "weighted avg       0.52      0.51      0.51      2235\n",
      "\n",
      "0.512751677852349\n",
      "0.5112987686488892\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(clean_words_str1)\n",
    "T = vectorizer.transform(clean_test_words_str1)\n",
    "\n",
    "X_train, Y_train = X.toarray(), tr['Insult'] \n",
    "X_test = T.toarray()\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "test_lowercase = []\n",
    "clean_test_words = []\n",
    "clean_test_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in te['Comment']:\n",
    "    test_lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(test_lowercase)):\n",
    "    \n",
    "    clean_test_words.append([token for token in test_lowercase[x] if not token in stop_words and token.isalpha()])\n",
    "    clean_test_words_str.append(\" \".join(clean_test_words[i]))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "lowercase = []\n",
    "clean_words = []\n",
    "clean_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in tr['Comment']:\n",
    "    lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(lowercase)):\n",
    "    \n",
    "    clean_words.append([token for token in lowercase[x] if not token in stop_words and token.isalpha()])\n",
    "    clean_words_str.append(\" \".join(clean_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52      1158\n",
      "           1       0.50      0.53      0.51      1077\n",
      "\n",
      "    accuracy                           0.52      2235\n",
      "   macro avg       0.52      0.52      0.52      2235\n",
      "weighted avg       0.52      0.52      0.52      2235\n",
      "\n",
      "0.516331096196868\n",
      "0.516411270642958\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(clean_words_str)\n",
    "T = vectorizer.transform(clean_test_words_str)\n",
    "\n",
    "X_train, Y_train = X.toarray(), tr['Insult'] \n",
    "X_test = T.toarray()\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase = []\n",
    "clean_words = []\n",
    "clean_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in tr['Comment']:\n",
    "    lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(lowercase)):\n",
    "    \n",
    "    clean_words.append([token for token in lowercase[x] if token.isalpha()])\n",
    "    clean_words_str.append(\" \".join(clean_words[i]))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lowercase = []\n",
    "clean_test_words = []\n",
    "clean_test_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in te['Comment']:\n",
    "    test_lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(test_lowercase)):\n",
    "    \n",
    "    clean_test_words.append([token for token in test_lowercase[x] if token.isalpha()])\n",
    "    clean_test_words_str.append(\" \".join(clean_test_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59      1158\n",
      "           1       0.55      0.51      0.53      1077\n",
      "\n",
      "    accuracy                           0.56      2235\n",
      "   macro avg       0.56      0.56      0.56      2235\n",
      "weighted avg       0.56      0.56      0.56      2235\n",
      "\n",
      "0.5610738255033557\n",
      "0.5601986774993744\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "X = vectorizer.fit_transform(clean_words_str)\n",
    "T = vectorizer.transform(clean_test_words_str)\n",
    "\n",
    "X_train, Y_train = X.toarray(), tr['Insult'] \n",
    "X_test = T.toarray()\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Smoothing Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase = []\n",
    "clean_words = []\n",
    "clean_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in tr['Comment']:\n",
    "    lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(lowercase)):\n",
    "    \n",
    "    clean_words.append([token for token in lowercase[x] if token.isalpha()])\n",
    "    clean_words_str.append(\" \".join(clean_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lowercase = []\n",
    "clean_test_words = []\n",
    "clean_test_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in te['Comment']:\n",
    "    test_lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(test_lowercase)):\n",
    "    \n",
    "    clean_test_words.append([token for token in test_lowercase[x] if token.isalpha()])\n",
    "    clean_test_words_str.append(\" \".join(clean_test_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.78      0.72      1158\n",
      "           1       0.71      0.58      0.64      1077\n",
      "\n",
      "    accuracy                           0.68      2235\n",
      "   macro avg       0.69      0.68      0.68      2235\n",
      "weighted avg       0.69      0.68      0.68      2235\n",
      "\n",
      "0.6832214765100671\n",
      "0.6794093192097572\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X2 = vectorizer.fit_transform(clean_words_str)\n",
    "T2 = vectorizer.transform(clean_test_words_str)\n",
    "\n",
    "X_train, Y_train = X2.toarray(), tr['Insult'] \n",
    "X_test = T2.toarray()\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "clf = MultinomialNB(alpha=1.0) # Laplace Smoothing\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The reason why we get better results in the Multinomial NB than the Gaussian Nb is because the Multinomial NB is used when we have discrete data. In text learning we have the count of each word to predict the class or label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of all 4 of the previous characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization and stopwords elimination of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "test_lowercase = []\n",
    "clean_test_words1 = []\n",
    "clean_test_words_str1 = []\n",
    "lemmatized_output_test = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "for word in te['Comment']:\n",
    "    test_lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "i=0\n",
    "for x in range(0,len(test_lowercase)):\n",
    "    \n",
    "    clean_test_words1.append([token for token in test_lowercase[x] if not token in stop_words and token.isalpha()])\n",
    "    lemmatized_output_test.append([lemmatizer.lemmatize(w,pos = \"v\") for w in clean_test_words1[i]])\n",
    "    clean_test_words_str1.append(\" \".join(lemmatized_output_test[i]))\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization and stopwords elimination of train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lowercase = []\n",
    "clean_words1 = []\n",
    "clean_words_str1 = []\n",
    "lemmatized_output = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "for word in tr['Comment']:\n",
    "    lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "i=0\n",
    "for x in range(0,len(lowercase)):\n",
    "    \n",
    "    clean_words1.append([token for token in lowercase[x] if not token in stop_words and token.isalpha()])\n",
    "    lemmatized_output.append([lemmatizer.lemmatize(w,pos = \"v\") for w in clean_words1[i]])\n",
    "    clean_words_str1.append(\" \".join(lemmatized_output[i]))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Naive Bayes classification for word vectors using bigrams and Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.70      1158\n",
      "           1       0.75      0.25      0.37      1077\n",
      "\n",
      "    accuracy                           0.60      2235\n",
      "   macro avg       0.66      0.59      0.54      2235\n",
      "weighted avg       0.66      0.60      0.54      2235\n",
      "\n",
      "0.5977628635346757\n",
      "0.5433499462866819\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "X2 = vectorizer.fit_transform(clean_words_str1)\n",
    "T2 = vectorizer.transform(clean_test_words_str1)\n",
    "\n",
    "X_train, Y_train = X2.toarray(), tr['Insult'] \n",
    "X_test = T2.toarray()\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "clf = MultinomialNB(alpha=1.0) # Laplace Smoothing\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_We have many comments and words that are very hard to process in the dataframe and that is why the scores did not improve after the lemmatization and the stopwords elimination._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g. n o tenho a m nima paci ncia pra esse tipo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Lemmatization can only apply to a certain part of speech and that is why instead of improving the classification i actually makes it more difficult._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g. \"is\" becomes \"be\" but \"oranges\" doesn't become \"orange\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf = tfidf_vectorizer.fit_transform(clean_words_str)\n",
    "\n",
    "tfidf_test = tfidf_vectorizer.transform(clean_test_words_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = []\n",
    "\n",
    "for i in range(0,len(clean_words_str)):\n",
    "    noun = 0\n",
    "    verb = 0\n",
    "    adv = 0\n",
    "    adj = 0\n",
    "    s = 0\n",
    "\n",
    "    text = word_tokenize(clean_words_str[i])\n",
    "    tagged = pos_tag(text)\n",
    "    \n",
    "    for word,j in tagged:\n",
    "        s += 1\n",
    "        if(j.startswith('NN')):\n",
    "            noun += 1\n",
    "        if(j.startswith('VB')):\n",
    "            verb += 1\n",
    "        if(j.startswith('RB')):\n",
    "            adv += 1\n",
    "        if(j.startswith('JJ')):\n",
    "            adj += 1\n",
    "\n",
    "\n",
    "    if(s==0):\n",
    "        freq.append([s,s,s,s])\n",
    "    else:\n",
    "        freq.append([noun/s, verb/s,adv/s,adj/s])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq1 = []\n",
    "\n",
    "for i in range(0,len(clean_test_words_str)):\n",
    "    noun = 0\n",
    "    verb = 0\n",
    "    adv = 0\n",
    "    adj = 0\n",
    "    s = 0\n",
    "\n",
    "    text = word_tokenize(clean_test_words_str[i])\n",
    "    tagged = pos_tag(text)\n",
    "    \n",
    "    for word,j in tagged:\n",
    "        s += 1\n",
    "        if(j.startswith('NN')):\n",
    "            noun += 1\n",
    "        if(j.startswith('VB')):\n",
    "            verb += 1\n",
    "        if(j.startswith('RB')):\n",
    "            adv += 1\n",
    "        if(j.startswith('JJ')):\n",
    "            adj += 1\n",
    "\n",
    "\n",
    "    if(s==0):\n",
    "        freq1.append([s,s,s,s])\n",
    "    else:\n",
    "        freq1.append([noun/s, verb/s,adv/s,adj/s])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of tf-idf and part-of-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.toarray().tolist()\n",
    "\n",
    "for i in range(0,len(clean_words_str)):\n",
    "    for j in range(0,4): \n",
    "        X[i].append(freq[i][j])\n",
    "        \n",
    "X_train = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = tfidf_test.toarray().tolist()\n",
    "\n",
    "for i in range(0,len(clean_test_words_str)):\n",
    "    for j in range(0,4): \n",
    "        Xt[i].append(freq1[i][j])\n",
    "        \n",
    "X_test = np.array(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76      1158\n",
      "           1       0.81      0.50      0.62      1077\n",
      "\n",
      "    accuracy                           0.70      2235\n",
      "   macro avg       0.73      0.70      0.69      2235\n",
      "weighted avg       0.73      0.70      0.69      2235\n",
      "\n",
      "0.7038031319910515\n",
      "0.6913780820909229\n"
     ]
    }
   ],
   "source": [
    "Y_train = tr['Insult']\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.97      0.73      1158\n",
      "           1       0.89      0.27      0.41      1077\n",
      "\n",
      "    accuracy                           0.63      2235\n",
      "   macro avg       0.74      0.62      0.57      2235\n",
      "weighted avg       0.73      0.63      0.58      2235\n",
      "\n",
      "0.6313199105145414\n",
      "0.5779406303263984\n"
     ]
    }
   ],
   "source": [
    "Y_train = tr['Insult']\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beat The Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Dataframe cleaning to improve f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\\\'\",\"'\",regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\@\",\"\",regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"n\\'t\", \" not\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'re\", \" are\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'s\", \" is\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'d\", \" would\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'ll\", \" will\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'t\", \" not\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'ve\", \" have\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'m\", \" am\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"\\'m\", \" am\", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"#\", \" \", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"%\", \" \", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"&\", \" \", regex = True)\n",
    "tr['Comment'] = tr['Comment'].str.replace(r\"*\", \" \", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase = []\n",
    "clean_words = []\n",
    "clean_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in tr['Comment']:\n",
    "    lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(lowercase)):\n",
    "    \n",
    "    clean_words.append([token for token in lowercase[x] if token.isalpha() and len(token) > 1])\n",
    "    clean_words_str.append(\" \".join(clean_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lowercase = []\n",
    "clean_test_words = []\n",
    "clean_test_words_str = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "for word in te['Comment']:\n",
    "    test_lowercase.append(tokenizer.tokenize(word.lower()))\n",
    "\n",
    "i=0\n",
    "for x in range(0,len(test_lowercase)):\n",
    "    \n",
    "    clean_test_words.append([token for token in test_lowercase[x] if token.isalpha() and len(token) > 1])\n",
    "    clean_test_words_str.append(\" \".join(clean_test_words[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.75      1158\n",
      "           1       0.77      0.59      0.67      1077\n",
      "\n",
      "    accuracy                           0.72      2235\n",
      "   macro avg       0.73      0.71      0.71      2235\n",
      "weighted avg       0.73      0.72      0.71      2235\n",
      "\n",
      "0.7172259507829978\n",
      "0.7122983972610082\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X2 = vectorizer.fit_transform(clean_words_str)\n",
    "T2 = vectorizer.transform(clean_test_words_str)\n",
    "\n",
    "X_train, Y_train = X2, tr['Insult'] \n",
    "X_test = T2\n",
    "Y_test = pd.read_csv('data/impermium_verification_labels.csv',usecols=[1])\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test,Y_pred) \n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1 score improves in the SVM classifier when we use the CountVectorizer instead of the TF-IDF\n",
    "- The score also improved slightly because we removed some unnecessary characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the complexity of the dataframe it is quite difficult to achieve really high scores. Also, in spite of removing stopwords or lemmatizing the data, we didn't see any imrovements and in some cases we noticed a slight downgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand we saw a big upgrade from GaussianNB to Laplace smoothing (the explanation is right below the related code). F1 score went from 0.518 to 0.68. We then saw a smaller upgrade when we used bigrams where the f1 score went from 0.518 to 0.56."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
